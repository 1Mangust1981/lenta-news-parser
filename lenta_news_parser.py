# Файл: lenta_news_parser.py
# Описание: Этот скрипт парсит новости с сайта Lenta.ru. Он извлекает заголовки
#           новостей, даты публикации и ссылки на статьи, а затем сохраняет всё в
#           CSV-файл. Код написан для новичков, чтобы было легко понять, что делает
#           каждая строка. Мы будем собирать данные с главной страницы Lenta.ru.
# Автор: 1Mangust1981
# Дата: 24 марта 2025

# Импортируем библиотеку requests, которая нужна для отправки HTTP-запросов
# HTTP-запросы — это способ загрузить веб-страницу (в нашем случае — Lenta.ru)
# Мы будем использовать requests.get() для получения HTML-кода страницы
import requests

# Импортируем BeautifulSoup из библиотеки bs4, чтобы парсить HTML-код страницы
# BeautifulSoup — это инструмент, который помогает находить элементы в HTML
# Например, мы сможем найти теги <a>, <h3>, <time> и извлечь из них данные
from bs4 import BeautifulSoup

# Импортируем библиотеку csv, чтобы сохранять данные в CSV-файл
# CSV — это формат файла, где данные разделены запятыми (например, title,date,url)
# Мы будем использовать эту библиотеку для записи новостей в файл lenta_news.csv
import csv

# Определяем URL страницы, которую будем парсить
# Это главная страница Lenta.ru, где отображаются последние новости
# URL — это адрес страницы в интернете, который мы будем загружать
URL = "https://lenta.ru"

# Функция fetch_news() отвечает за загрузку страницы и извлечение данных о новостях
# Она возвращает список словарей, где каждый словарь — это новость с заголовком,
# датой и ссылкой (например, {"title": "Новость", "date": "25 марта", "url": "..."})
def fetch_news():
    # Создаём пустой список news_list, куда будем добавлять данные о новостях
    # Список будет содержать словари вида {"title": "Заголовок", "date": "Дата",
    # "url": "Ссылка"}
    news_list = []

    # Используем try-except, чтобы поймать возможные ошибки при выполнении кода
    # Например, если страница не загрузится или будет ошибка сети, мы не хотим,
    # чтобы программа крашилась, а просто вывела сообщение об ошибке
    try:
        # Выводим сообщение в терминал, чтобы пользователь знал, что происходит
        # Это помогает понять, на каком этапе находится выполнение программы
        # Мы сообщаем, что начинаем загружать страницу Lenta.ru
        print("Запрашиваю страницу Lenta.ru...")

        # Отправляем GET-запрос к URL с помощью requests.get()
        # GET-запрос — это способ запросить данные с веб-страницы
        # Мы добавляем заголовок User-Agent, чтобы Lenta.ru думала, что запрос
        # отправлен из браузера, а не из скрипта (иначе нас могут заблокировать)
        # User-Agent — это строка, которая имитирует браузер (например, Chrome)
        response = requests.get(URL, headers={
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
                          "AppleWebKit/537.36"
        })

        # Проверяем, что запрос успешен, с помощью raise_for_status()
        # Если статус-код не 200 (например, 404 — страница не найдена, или 500 —
        # ошибка сервера), будет вызвано исключение
        # Это помогает избежать работы с пустой или ошибочной страницей
        response.raise_for_status()

        # Парсим HTML-код страницы с помощью BeautifulSoup
        # response.text — это HTML-код страницы в виде строки
        # "html.parser" — это парсер, который BeautifulSoup использует для анализа
        # HTML-кода, чтобы мы могли искать теги и извлекать данные
        soup = BeautifulSoup(response.text, "html.parser")

        # Ищем все карточки новостей на странице
        # На Lenta.ru новости отображаются в тегах <a> с классом "card-mini"
        # Метод find_all() возвращает список всех тегов <a>, у которых есть класс
        # "card-mini", то есть все карточки новостей на главной странице
        news_cards = soup.find_all("a", class_="card-mini")

        # Проходим по всем найденным карточкам новостей в цикле for
        # Каждая карточка (card) — это тег <a>, который содержит заголовок, дату
        # и ссылку на новость
        for card in news_cards:
            # Извлекаем заголовок новости
            # Заголовок находится в теге <h3> с классом "card-mini__title"
            # Метод find() ищет первый тег <h3> с указанным классом внутри карточки
            title = card.find("h3", class_="card-mini__title")

            # Проверяем, что заголовок был найден
            # Если title не None, значит, мы нашли тег <h3> с заголовком
            if title:
                # Извлекаем текст заголовка с помощью get_text()
                # strip=True убирает лишние пробелы и переносы строк
                # Например, если в HTML написано "  Новость  ", мы получим "Новость"
                title_text = title.get_text(strip=True)
            else:
                # Если заголовок не найден, пропускаем эту карточку
                # Мы используем continue, чтобы перейти к следующей карточке
                continue

            # Извлекаем дату новости
            # Дата находится в теге <time> с классом "card-mini__date"
            # Метод find() ищет первый тег <time> с указанным классом
            date = card.find("time", class_="card-mini__date")

            # Проверяем, что дата была найдена
            # Если date не None, значит, мы нашли тег <time> с датой
            if date:
                # Извлекаем текст даты с помощью get_text()
                # strip=True убирает лишние пробелы
                # Например, мы можем получить "25 марта 2025"
                date_text = date.get_text(strip=True)
            else:
                # Если дата не найдена, задаём значение по умолчанию
                # Это нужно, чтобы в CSV не было пустых ячеек
                date_text = "Не указано"

            # Извлекаем ссылку на новость
            # Ссылка находится в атрибуте href тега <a> (то есть самой карточки)
            # Метод get("href") извлекает значение атрибута href
            # Например, href может быть "/news/2025/03/25/crisis/"
            href = card.get("href")

            # Проверяем, что ссылка была найдена
            # Если href не None, значит, у карточки есть атрибут href
            if href:
                # Проверяем, является ли ссылка относительной
                # Относительная ссылка начинается с "/", например, "/news/2025/..."
                # Если ссылка относительная, мы добавляем домен "https://lenta.ru"
                if href.startswith("/"):
                    # Создаём полную ссылку, добавляя домен к относительной ссылке
                    # Например, из "/news/2025/03/25/crisis/" получаем
                    # "https://lenta.ru/news/2025/03/25/crisis/"
                    full_url = f"https://lenta.ru{href}"
                else:
                    # Если ссылка уже полная (например, "https://lenta.ru/..."),
                    # оставляем её как есть
                    full_url = href
            else:
                # Если ссылка не найдена, пропускаем эту карточку
                # Мы используем continue, чтобы перейти к следующей карточке
                continue

            # Добавляем новость в список news_list
            # Создаём словарь с тремя ключами: title, date и url
            # title — это заголовок новости
            # date — это дата публикации
            # url — это полная ссылка на статью
            news_list.append({
                "title": title_text,
                "date": date_text,
                "url": full_url
            })

        # Выводим в терминал количество найденных новостей
        # len(news_list) возвращает длину списка news_list, то есть число новостей
        # Это помогает понять, сколько данных мы собрали
        print(f"Найдено новостей: {len(news_list)}")

        # Возвращаем список новостей, чтобы его можно было использовать дальше
        # Например, передать в функцию save_to_csv()
        return news_list

    # Обрабатываем возможные ошибки, которые могут возникнуть в блоке try
    except Exception as error:
        # Выводим сообщение об ошибке в терминал
        # str(error) преобразует ошибку в строку, чтобы её можно было напечатать
        # Например, это может быть "404 Client Error: Not Found"
        print(f"Ошибка при запросе: {error}")

        # Возвращаем пустой список, если произошла ошибка
        # Это нужно, чтобы программа не крашилась, а продолжила работу
        return []

# Функция save_to_csv() сохраняет список новостей в CSV-файл
# Она принимает список новостей и имя файла (по умолчанию "lenta_news.csv")
def save_to_csv(news_list, filename="lenta_news.csv"):
    # Проверяем, есть ли данные в списке news_list
    # Если список пустой, нет смысла создавать файл
    if not news_list:
        # Выводим сообщение, что данных для сохранения нет
        print("Нет данных для сохранения")

        # Выходим из функции с помощью return
        # Это предотвращает дальнейшее выполнение кода в функции
        return

    # Открываем файл для записи с помощью with open()
    # "w" — режим записи (если файл существует, он будет перезаписан)
    # newline="" — убирает лишние пустые строки в CSV
    # encoding="utf-8" — используем кодировку UTF-8, чтобы поддерживать русские
    # буквы (например, в заголовках новостей)
    with open(filename, "w", newline="", encoding="utf-8") as file:
        # Создаём объект DictWriter для записи словарей в CSV
        # fieldnames — это список столбцов (title, date, url)
        # DictWriter автоматически создаёт CSV с этими столбцами
        writer = csv.DictWriter(file, fieldnames=["title", "date", "url"])

        # Записываем заголовок CSV-файла
        # Это будет первая строка: "title,date,url"
        # writeheader() автоматически записывает названия столбцов
        writer.writeheader()

        # Записываем все новости в файл
        # writerows() принимает список словарей и записывает их как строки CSV
        # Например, {"title": "Новость", "date": "25 марта", "url": "..."} станет
        # строкой "Новость,25 марта,..."
        writer.writerows(news_list)

    # Выводим сообщение, что данные успешно сохранены
    # Указываем имя файла, чтобы пользователь знал, куда сохранились данные
    print(f"Данные сохранены в {filename}")

# Функция main() — это основная функция, которая запускает весь процесс
# Она вызывает другие функции (fetch_news и save_to_csv) в нужном порядке
def main():
    # Выводим сообщение, что начинаем парсинг
    # Это помогает пользователю понять, что программа начала работать
    print("Начинаю парсинг Lenta.ru...")

    # Вызываем функцию fetch_news(), чтобы получить список новостей
    # Результат сохраняем в переменную news
    news = fetch_news()

    # Выводим сообщение, что начинаем сохранять данные
    # Это помогает пользователю следить за процессом
    print("Сохраняю данные в файл...")

    # Вызываем функцию save_to_csv(), чтобы сохранить новости в файл
    # Передаём список новостей и имя файла по умолчанию
    save_to_csv(news)

    # Выводим итоговое сообщение с количеством найденных новостей
    # Это даёт пользователю понять, сколько данных было собрано
    print(f"Готово! Найдено новостей: {len(news)}")

# Проверяем, запущен ли скрипт напрямую (а не импортирован как модуль)
# Это стандартная конструкция в Python, которая позволяет запускать код только
# при прямом запуске файла (например, python3 lenta_news_parser.py)
if __name__ == "__main__":
    # Если скрипт запущен напрямую, вызываем функцию main()
    # Это запускает весь процесс парсинга и сохранения
    main()
